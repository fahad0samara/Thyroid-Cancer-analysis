{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thyroid Cancer Prediction - Advanced Machine Learning\n",
    "\n",
    "## Sections:\n",
    "1. Data Preprocessing\n",
    "2. Feature Engineering\n",
    "3. Model Development\n",
    "4. Hyperparameter Tuning\n",
    "5. Ensemble Methods\n",
    "6. Model Evaluation\n",
    "7. Feature Importance\n",
    "8. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "df = pd.read_csv('thyroid_cancer_risk_data.csv')\n",
    "\n",
    "# Define features\n",
    "categorical_vars = ['Gender', 'Country', 'Ethnicity', 'Family_History', \n",
    "                   'Radiation_Exposure', 'Iodine_Deficiency', 'Smoking', \n",
    "                   'Obesity', 'Diabetes']\n",
    "numerical_vars = ['Age', 'TSH_Level', 'T3_Level', 'T4_Level', 'Nodule_Size']\n",
    "\n",
    "# Feature Engineering\n",
    "# 1. Create risk score\n",
    "df['Risk_Score'] = (\n",
    "    (df['Family_History'] == 'Yes').astype(int) * 2 +\n",
    "    (df['Radiation_Exposure'] == 'Yes').astype(int) * 1.5 +\n",
    "    (df['Iodine_Deficiency'] == 'Yes').astype(int) * 1.5 +\n",
    "    (df['Smoking'] == 'Yes').astype(int) +\n",
    "    (df['Obesity'] == 'Yes').astype(int) +\n",
    "    (df['Diabetes'] == 'Yes').astype(int)\n",
    ")\n",
    "\n",
    "# 2. Create hormone ratios\n",
    "df['TSH_T3_Ratio'] = df['TSH_Level'] / df['T3_Level']\n",
    "df['TSH_T4_Ratio'] = df['TSH_Level'] / df['T4_Level']\n",
    "df['T3_T4_Ratio'] = df['T3_Level'] / df['T4_Level']\n",
    "\n",
    "# 3. Create age groups\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 30, 45, 60, 75, 100], \n",
    "                        labels=['<30', '30-45', '45-60', '60-75', '>75'])\n",
    "\n",
    "# 4. Create interaction features\n",
    "df['Age_TSH'] = df['Age'] * df['TSH_Level']\n",
    "df['Nodule_TSH'] = df['Nodule_Size'] * df['TSH_Level']\n",
    "\n",
    "# Prepare features for modeling\n",
    "# Add engineered features to the list\n",
    "numerical_vars += ['Risk_Score', 'TSH_T3_Ratio', 'TSH_T4_Ratio', 'T3_T4_Ratio', \n",
    "                   'Age_TSH', 'Nodule_TSH']\n",
    "categorical_vars += ['Age_Group']\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[categorical_vars + numerical_vars].copy()\n",
    "y = (df['Diagnosis'] == 'Malignant').astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in categorical_vars:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_vars] = scaler.fit_transform(X_train[numerical_vars])\n",
    "X_test[numerical_vars] = scaler.transform(X_test[numerical_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Development with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def objective_xgb(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Optimize XGBoost\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "\n",
    "# Get best XGBoost model\n",
    "best_xgb = XGBClassifier(**study_xgb.best_params)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Optimize LightGBM\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "\n",
    "# Get best LightGBM model\n",
    "best_lgb = LGBMClassifier(**study_lgb.best_params)\n",
    "best_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Create CatBoost model\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('lgb', best_lgb),\n",
    "        ('catboost', catboost)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Create stacking classifier\n",
    "estimators = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('catboost', catboost)\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit ensemble models\n",
    "voting_clf.fit(X_train, y_train)\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dictionary of models\n",
    "models = {\n",
    "    'XGBoost': best_xgb,\n",
    "    'LightGBM': best_lgb,\n",
    "    'CatBoost': catboost,\n",
    "    'Voting': voting_clf,\n",
    "    'Stacking': stacking_clf\n",
    "}\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'classification_report': classification_report(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Different Models')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"ROC AUC: {result['roc_auc']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(result['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# SHAP values for feature importance\n",
    "explainer = shap.TreeExplainer(best_xgb)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP summary\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "plt.title('Feature Importance (SHAP values)')\n",
    "plt.show()\n",
    "\n",
    "# Plot detailed SHAP values\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "plt.title('SHAP Value Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get best model\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['roc_auc'])[0]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Create prediction function\n",
    "def predict_thyroid_cancer(patient_data):\n",
    "    # Preprocess patient data\n",
    "    patient_df = pd.DataFrame([patient_data])\n",
    "    \n",
    "    # Apply same preprocessing steps\n",
    "    for col in categorical_vars:\n",
    "        patient_df[col] = le.fit_transform(patient_df[col])\n",
    "    \n",
    "    patient_df[numerical_vars] = scaler.transform(patient_df[numerical_vars])\n",
    "    \n",
    "    # Make prediction\n",
    "    prob = best_model.predict_proba(patient_df)[0, 1]\n",
    "    prediction = 'Malignant' if prob > 0.5 else 'Benign'\n",
    "    \n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'probability': prob,\n",
    "        'risk_level': 'High' if prob > 0.7 else 'Medium' if prob > 0.3 else 'Low'\n",
    "    }\n",
    "\n",
    "# Save best model and preprocessing objects\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_thyroid_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(le, 'label_encoder.joblib')\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"ROC AUC Score: {results[best_model_name]['roc_auc']:.4f}\")\n",
    "\n",
    "# Example prediction\n",
    "example_patient = {\n",
    "    'Age': 45,\n",
    "    'Gender': 'Female',\n",
    "    'Country': 'USA',\n",
    "    'Ethnicity': 'Caucasian',\n",
    "    'Family_History': 'No',\n",
    "    'Radiation_Exposure': 'No',\n",
    "    'Iodine_Deficiency': 'No',\n",
    "    'Smoking': 'No',\n",
    "    'Obesity': 'No',\n",
    "    'Diabetes': 'No',\n",
    "    'TSH_Level': 2.5,\n",
    "    'T3_Level': 1.8,\n",
    "    'T4_Level': 8.0,\n",
    "    'Nodule_Size': 1.5\n",
    "}\n",
    "\n",
    "prediction_result = predict_thyroid_cancer(example_patient)\n",
    "print(\"\\nExample Prediction:\")\n",
    "print(prediction_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
